{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abe0b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "from operator import mod\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import *\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0ea8dc",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "label_array = {\n",
    "    0: \"top\",\n",
    "    1: \"trouser\",\n",
    "    2: \"pullover\",\n",
    "    3: \"dress\",\n",
    "    4: \"coat\",\n",
    "    5: \"sandal\",\n",
    "    6: \"shirt\",\n",
    "    7: \"sneaker\",\n",
    "    8: \"bag\",\n",
    "    9: \"ankle_boot\",\n",
    "}\n",
    "\n",
    "\n",
    "def return_shape(tes):\n",
    "    print(tes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92290c24",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def print_shapes(arr):\n",
    "    for i in arr:\n",
    "        return_shape(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd575299",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def visualize_image(features, res_path):\n",
    "    for i in range(25):\n",
    "        plt.subplot(5, 5, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.imshow(features[i].reshape(28, 28))\n",
    "    # plt.show()\n",
    "    plt.savefig(f\"{res_path}/dataset_image.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0254ff02",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def load_data(main_path, subset=None):\n",
    "    df_train = pd.read_csv(str(main_path / \"fashion-mnist_train.csv\"))\n",
    "    df_test = pd.read_csv(str(main_path / \"fashion-mnist_test.csv\"))\n",
    "    print(df_train.head(5))\n",
    "\n",
    "    if subset != None and subset > 0:\n",
    "        df_train = df_train.head(subset)\n",
    "        df_test = df_test.head(subset)\n",
    "\n",
    "    train_features, val_features, train_labels, val_labels = train_test_split(\n",
    "        df_train.drop(\"label\", axis=1), df_train[\"label\"], test_size=0.2\n",
    "    )\n",
    "    test_features, test_labels = df_test.drop(\"label\", axis=1), df_test[\"label\"]\n",
    "    (\n",
    "        train_features,\n",
    "        val_features,\n",
    "        train_labels,\n",
    "        val_labels,\n",
    "        test_features,\n",
    "        test_labels,\n",
    "    ) = (\n",
    "        train_features.to_numpy(),\n",
    "        val_features.to_numpy(),\n",
    "        train_labels.to_numpy(),\n",
    "        val_labels.to_numpy(),\n",
    "        test_features.to_numpy(),\n",
    "        test_labels.to_numpy(),\n",
    "    )\n",
    "    print(\"[INFO] DONE LOADING DATA\")\n",
    "    return (\n",
    "        train_features,\n",
    "        val_features,\n",
    "        train_labels,\n",
    "        val_labels,\n",
    "        test_features,\n",
    "        test_labels,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f631b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML PIPELINE\n",
    "\n",
    "\n",
    "def preproces_skeleton(array, process=np.flip):\n",
    "    # currently does for all images in array\n",
    "    # TODO : Add results to the array\n",
    "    if process == None:\n",
    "        return array\n",
    "    else:\n",
    "        for i in range(array.shape[0]):\n",
    "            array[i] = process(array[i])\n",
    "        return array\n",
    "\n",
    "\n",
    "def dimensionality_reduction(X, X_test, method=\"pca\"):\n",
    "    if method == \"pca\":\n",
    "        pca = PCA(0.85)\n",
    "        pca.fit(X)\n",
    "        X = pca.transform(X)\n",
    "        X_test = pca.transform(X_test)\n",
    "\n",
    "\n",
    "def train_and_predict(\n",
    "    train_features,\n",
    "    test_features,\n",
    "    train_labels,\n",
    "    test_labels,\n",
    "    model,\n",
    "    metrics,\n",
    "    res_path,\n",
    "    reduce_dims=None,\n",
    "    folds=10,\n",
    "):\n",
    "    # scale data\n",
    "    X_orig = StandardScaler().fit_transform(train_features)\n",
    "    X_test_orig = StandardScaler().fit_transform(test_features)\n",
    "    train_labels_orig, test_labels_orig = train_labels.copy(), test_labels.copy()\n",
    "\n",
    "    # preprocess_step\n",
    "    X_orig = preproces_skeleton(X_orig, None)\n",
    "    if reduce_dims != None:\n",
    "        dimensionality_reduction(X_orig, X_test_orig, reduce_dims)\n",
    "\n",
    "    dict_results = {x.__name__: [] for x in metrics}\n",
    "\n",
    "    # cross validation\n",
    "    kf = KFold(n_splits=folds, shuffle=True)\n",
    "\n",
    "    for train_indices, test_indices in tqdm(kf.split(X_orig), total=folds):\n",
    "        X = X_orig[train_indices]\n",
    "        train_labels = train_labels_orig[train_indices]\n",
    "        X_test = X_test_orig[test_indices]\n",
    "        test_labels = test_labels_orig[test_indices]\n",
    "\n",
    "        # fit model\n",
    "        model.fit(X, train_labels)\n",
    "\n",
    "        y1 = test_labels\n",
    "        y2 = model.predict(X_test)\n",
    "\n",
    "        # metrics\n",
    "        if type(metrics) != list:\n",
    "            metrics = [metrics]\n",
    "\n",
    "        for metric in metrics:\n",
    "            try:\n",
    "                dict_results[metric.__name__].append(metric(y1, y2))\n",
    "            except ValueError:\n",
    "                dict_results[metric.__name__].append(metric(y1, y2, average=\"macro\"))\n",
    "\n",
    "    # print(dict_results)\n",
    "    for metric in dict_results:\n",
    "        dict_results[metric] = np.mean(dict_results[metric])\n",
    "        # dict_results[method][res_arr] = np.mean(dict_results[method][res_arr])\n",
    "\n",
    "    plt.cla()\n",
    "    plt.clf()\n",
    "    plot_confusion_matrix(model, X_test, test_labels)\n",
    "    plt.savefig(f\"{res_path}/confusion_{str(model)}.png\")\n",
    "\n",
    "    return dict_results\n",
    "\n",
    "\n",
    "def multi_model_run(\n",
    "    train_features,\n",
    "    test_features,\n",
    "    train_labels,\n",
    "    test_labels,\n",
    "    model_list,\n",
    "    reduce_dims,\n",
    "    metrics,\n",
    "    res_path,\n",
    "    folds=10,\n",
    "):\n",
    "    final_dict_results = {}\n",
    "    for model in tqdm(model_list):\n",
    "        final_dict_results[str(model)] = train_and_predict(\n",
    "            train_features=train_features,\n",
    "            test_features=test_features,\n",
    "            train_labels=train_labels,\n",
    "            test_labels=test_labels,\n",
    "            model=model,\n",
    "            reduce_dims=reduce_dims,\n",
    "            metrics=metrics,\n",
    "            res_path=res_path,\n",
    "            folds=folds,\n",
    "        )\n",
    "    print(final_dict_results)\n",
    "    df = pd.DataFrame.from_dict(final_dict_results)\n",
    "    df.to_csv(f\"{res_path}/outputs.csv\", mode=\"a\")\n",
    "    return final_dict_results"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}