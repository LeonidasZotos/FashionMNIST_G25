{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ce2d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c661b26",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "main_path = Path(os.getcwd()).parent / \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed4a5b9",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def return_shape(tes):\n",
    "    print(tes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade7c39c",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def print_shapes(arr):\n",
    "    for i in arr:\n",
    "        return_shape(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526e6600",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def visualize_image(features):\n",
    "    for i in range(25):\n",
    "        plt.subplot(5, 5, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        # imshow  takes an array ( with dimension = 2, RGB or B/W) and gives you the image that corresponds to it\n",
    "        plt.imshow(features[i].reshape(28, 28))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1af5fa9",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def load_data(main_path, subset=None):\n",
    "    df_train = pd.read_csv(str(main_path / \"fashion-mnist_train.csv\"))\n",
    "    df_test = pd.read_csv(str(main_path / \"fashion-mnist_test.csv\"))\n",
    "    print(df_train.head(5))\n",
    "\n",
    "    if subset != None and subset > 0:\n",
    "        df_train = df_train.head(subset)\n",
    "        df_test = df_test.head(subset)\n",
    "\n",
    "    train_features, val_features, train_labels, val_labels = train_test_split(\n",
    "        df_train.drop(\"label\", axis=1), df_train[\"label\"], test_size=0.2\n",
    "    )\n",
    "    test_features, test_labels = df_test.drop(\"label\", axis=1), df_test[\"label\"]\n",
    "    (\n",
    "        train_features,\n",
    "        val_features,\n",
    "        train_labels,\n",
    "        val_labels,\n",
    "        test_features,\n",
    "        test_labels,\n",
    "    ) = (\n",
    "        train_features.to_numpy(),\n",
    "        val_features.to_numpy(),\n",
    "        train_labels.to_numpy(),\n",
    "        val_labels.to_numpy(),\n",
    "        test_features.to_numpy(),\n",
    "        test_labels.to_numpy(),\n",
    "    )\n",
    "    print(\"[INFO] DONE LOADING DATA\")\n",
    "    return (\n",
    "        train_features,\n",
    "        val_features,\n",
    "        train_labels,\n",
    "        val_labels,\n",
    "        test_features,\n",
    "        test_labels,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d632f4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML PIPELINE\n",
    "\n",
    "\n",
    "def preproces_skeleton(array, process=np.flip):\n",
    "    # currently does for all images in array\n",
    "    # TODO : Add results to the array\n",
    "    if process == None:\n",
    "        return array\n",
    "    else:\n",
    "        for i in range(array.shape[0]):\n",
    "            array[i] = process(array[i])\n",
    "        return array\n",
    "\n",
    "\n",
    "def train_and_predict(train_features, test_features, model, metrics, normalize=True):\n",
    "    # scale data\n",
    "    X = StandardScaler().fit_transform(train_features)\n",
    "    X_test = StandardScaler().fit_transform(test_features)\n",
    "\n",
    "    # preprocess_step\n",
    "    X = preproces_skeleton(X, None)\n",
    "\n",
    "    # fit model\n",
    "    model.fit(X, train_labels)\n",
    "    y1 = test_labels\n",
    "    y2 = model.predict(X_test)\n",
    "\n",
    "    # metrics\n",
    "    if type(metrics) != list:\n",
    "        metrics = [metrics]\n",
    "\n",
    "    dict_results = {}\n",
    "    for metric in metrics:\n",
    "        try:\n",
    "            dict_results[metric.__name__] = metric(y1, y2)\n",
    "        except ValueError:\n",
    "            dict_results[metric.__name__] = metric(y1, y2, average=\"macro\")\n",
    "\n",
    "    print(dict_results)\n",
    "    return dict_results\n",
    "\n",
    "\n",
    "def multi_model_run(train_features, test_features, model_list, metrics):\n",
    "    final_dict_results = {}\n",
    "    for model in tqdm(model_list):\n",
    "        final_dict_results[str(model)] = train_and_predict(\n",
    "            train_features=train_features,\n",
    "            test_features=test_features,\n",
    "            model=model,\n",
    "            metrics=metrics,\n",
    "        )\n",
    "    print(final_dict_results)\n",
    "    return final_dict_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b194fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ DATA : Dont forget to remove subset (set to None for full data)\n",
    "(\n",
    "    train_features,\n",
    "    val_features,\n",
    "    train_labels,\n",
    "    val_labels,\n",
    "    test_features,\n",
    "    test_labels,\n",
    ") = load_data(main_path=main_path, subset=None)\n",
    "print_shapes(\n",
    "    [train_features, val_features, train_labels, val_labels, test_features, test_labels]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea1f5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEE IF READING WORKED\n",
    "visualize_image(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa96e80e",
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "Run entire pipeline"
   },
   "outputs": [],
   "source": [
    "multi_model_run(\n",
    "    train_features=train_features,\n",
    "    test_features=test_features,\n",
    "    model_list=[\n",
    "        KNeighborsClassifier(n_neighbors=3),\n",
    "        RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    ],\n",
    "    metrics=[\n",
    "        accuracy_score,\n",
    "        precision_score,\n",
    "        recall_score,\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d367da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "title,-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
