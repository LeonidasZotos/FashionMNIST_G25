{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20088bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from operator import mod\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import *\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31887f52",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "label_array = {\n",
    "    0: \"top\",\n",
    "    1: \"trouser\",\n",
    "    2: \"pullover\",\n",
    "    3: \"dress\",\n",
    "    4: \"coat\",\n",
    "    5: \"sandal\",\n",
    "    6: \"shirt\",\n",
    "    7: \"sneaker\",\n",
    "    8: \"bag\",\n",
    "    9: \"ankle_boot\",\n",
    "}\n",
    "\n",
    "\n",
    "def return_shape(tes):\n",
    "    print(tes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a931ade0",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def print_shapes(arr):\n",
    "    for i in arr:\n",
    "        return_shape(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efd96f4",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def visualize_image(features):\n",
    "    for i in range(25):\n",
    "        plt.subplot(5, 5, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.imshow(features[i].reshape(28, 28))\n",
    "    # plt.show()\n",
    "    plt.savefig(\"outputs/dataset_image.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d364218",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def load_data(main_path, subset=None):\n",
    "    df_train = pd.read_csv(str(main_path / \"fashion-mnist_train.csv\"))\n",
    "    df_test = pd.read_csv(str(main_path / \"fashion-mnist_test.csv\"))\n",
    "    print(df_train.head(5))\n",
    "\n",
    "    if subset != None and subset > 0:\n",
    "        df_train = df_train.head(subset)\n",
    "        df_test = df_test.head(subset)\n",
    "\n",
    "    train_features, val_features, train_labels, val_labels = train_test_split(\n",
    "        df_train.drop(\"label\", axis=1), df_train[\"label\"], test_size=0.2\n",
    "    )\n",
    "    test_features, test_labels = df_test.drop(\"label\", axis=1), df_test[\"label\"]\n",
    "    (\n",
    "        train_features,\n",
    "        val_features,\n",
    "        train_labels,\n",
    "        val_labels,\n",
    "        test_features,\n",
    "        test_labels,\n",
    "    ) = (\n",
    "        train_features.to_numpy(),\n",
    "        val_features.to_numpy(),\n",
    "        train_labels.to_numpy(),\n",
    "        val_labels.to_numpy(),\n",
    "        test_features.to_numpy(),\n",
    "        test_labels.to_numpy(),\n",
    "    )\n",
    "    print(\"[INFO] DONE LOADING DATA\")\n",
    "    return (\n",
    "        train_features,\n",
    "        val_features,\n",
    "        train_labels,\n",
    "        val_labels,\n",
    "        test_features,\n",
    "        test_labels,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414f7f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML PIPELINE\n",
    "\n",
    "\n",
    "def preproces_skeleton(array, process=np.flip):\n",
    "    # currently does for all images in array\n",
    "    # TODO : Add results to the array\n",
    "    if process == None:\n",
    "        return array\n",
    "    else:\n",
    "        for i in range(array.shape[0]):\n",
    "            array[i] = process(array[i])\n",
    "        return array\n",
    "\n",
    "\n",
    "def dimensionality_reduction(X, X_test, method=\"pca\"):\n",
    "    if method == \"pca\":\n",
    "        pca = PCA(0.85)\n",
    "        pca.fit(X)\n",
    "        X = pca.transform(X)\n",
    "        X_test = pca.transform(X_test)\n",
    "\n",
    "\n",
    "def train_and_predict(\n",
    "    train_features,\n",
    "    test_features,\n",
    "    train_labels,\n",
    "    test_labels,\n",
    "    model,\n",
    "    metrics,\n",
    "    reduce_dims=None,\n",
    "):\n",
    "    # scale data\n",
    "    X = StandardScaler().fit_transform(train_features)\n",
    "    X_test = StandardScaler().fit_transform(test_features)\n",
    "\n",
    "    # preprocess_step\n",
    "    X = preproces_skeleton(X, None)\n",
    "    if reduce_dims != None:\n",
    "        dimensionality_reduction(X, X_test, reduce_dims)\n",
    "\n",
    "    # fit model\n",
    "    model.fit(X, train_labels)\n",
    "\n",
    "    y1 = test_labels\n",
    "    y2 = model.predict(X_test)\n",
    "\n",
    "    # metrics\n",
    "    if type(metrics) != list:\n",
    "        metrics = [metrics]\n",
    "\n",
    "    dict_results = {}\n",
    "    for metric in metrics:\n",
    "        try:\n",
    "            dict_results[metric.__name__] = metric(y1, y2)\n",
    "        except ValueError:\n",
    "            dict_results[metric.__name__] = metric(y1, y2, average=\"macro\")\n",
    "\n",
    "    plt.cla()\n",
    "    plt.clf()\n",
    "    plot_confusion_matrix(model, X_test, test_labels)\n",
    "    plt.savefig(f\"outputs/confusion_{str(model)}.png\")\n",
    "\n",
    "    print(dict_results)\n",
    "    return dict_results\n",
    "\n",
    "\n",
    "def multi_model_run(\n",
    "    train_features,\n",
    "    test_features,\n",
    "    train_labels,\n",
    "    test_labels,\n",
    "    model_list,\n",
    "    reduce_dims,\n",
    "    metrics,\n",
    "):\n",
    "    final_dict_results = {}\n",
    "    for model in tqdm(model_list):\n",
    "        final_dict_results[str(model)] = train_and_predict(\n",
    "            train_features=train_features,\n",
    "            test_features=test_features,\n",
    "            train_labels=train_labels,\n",
    "            test_labels=test_labels,\n",
    "            model=model,\n",
    "            reduce_dims=reduce_dims,\n",
    "            metrics=metrics,\n",
    "        )\n",
    "    print(final_dict_results)\n",
    "    df = pd.DataFrame.from_dict(final_dict_results)\n",
    "    df.to_csv(\"outputs/outputs.csv\", mode=\"a\")\n",
    "    return final_dict_results"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
